{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-17T09:13:03.970938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "%load_ext cudf.pandas\n",
    "import math\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from safetensors.torch import save_file\n",
    "from tqdm import tqdm"
   ],
   "id": "202e81b920411b31",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BracklyMurunga\\Desktop\\AI SUNDAYS\\PlayGenie\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Encoding songs:   0%|          | 0/4757 [00:00<?, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Configuration constants\n",
    "CONTEXT_SIZE = 11\n",
    "DATA_PATH = \"/content/spotify_dataset.csv\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "OUTPUT_FILE = \"spotify_dataset.safetensors\"\n",
    "TRAIN_RATIO = 0.6\n",
    "VAL_RATIO = 0.2  # Test ratio = 1 - TRAIN_RATIO - VAL_RATIO\n",
    "\n",
    "def save_song_embeddings(song_embeddings:dict[str, np.ndarray]):\n",
    "    json.dump(song_embeddings, open(\"song_embeddings.json\", \"w\"))\n",
    "    print(\"Saved song embeddings\")\n",
    "    return True\n",
    "\n",
    "def clean_column_names(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Strip whitespace and remove quotes from column names\"\"\"\n",
    "    return df.rename(columns=lambda x: x.strip().replace('\"', ''))\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"Clean and normalize text data\"\"\"\n",
    "    return str(text).strip().lower()\n",
    "\n",
    "def preprocess_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Process raw dataframe into playlist-song groupings\"\"\"\n",
    "    # Clean text data\n",
    "    df = df.map(lambda x: preprocess_text(x) if pd.notna(x) else x)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Combine track and artist information\n",
    "    df['trackname'] = df['trackname'] + ' by ' + df['artistname']\n",
    "\n",
    "    # Group playlists and filter by size\n",
    "    playlist_df = (\n",
    "            df.groupby('playlistname', as_index=False)\n",
    "            .agg(tracklist=('trackname', list))\n",
    "        )\n",
    "    playlist_df = playlist_df[playlist_df['tracklist'].map(len) > 40].reset_index(drop=True)\n",
    "\n",
    "    return playlist_df[['tracklist']]\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    df = pd.read_csv(DATA_PATH, on_bad_lines='skip')\n",
    "    df = clean_column_names(df)\n",
    "    processed_df = preprocess_dataframe(df)\n",
    "\n",
    "    # Initialize embedding model\n",
    "    encoder = SentenceTransformer(EMBEDDING_MODEL,device='cuda')\n",
    "\n",
    "    # Precompute song embeddings (unique songs only)\n",
    "    unique_songs = set(song for tracklist in processed_df['tracklist'] for song in tracklist)\n",
    "    song_embeddings = {song: encoder.encode(song) for song in tqdm(unique_songs, desc=\"Encoding songs\")}\n",
    "    save_song_embeddings(song_embeddings)\n",
    "    # Split data into chunks and create datasets\n",
    "    train, val, test = [], [], []\n",
    "\n",
    "    for tracklist in tqdm(processed_df['tracklist'], desc=\"Processing playlists\"):\n",
    "        n_chunks = len(tracklist) // CONTEXT_SIZE\n",
    "        if n_chunks < 1:\n",
    "            continue\n",
    "\n",
    "        # Create fixed-size chunks\n",
    "        chunks = [\n",
    "            tracklist[i * CONTEXT_SIZE : (i + 1) * CONTEXT_SIZE]\n",
    "            for i in range(n_chunks)\n",
    "        ]\n",
    "\n",
    "        # Split chunks according to ratios\n",
    "        train_end = math.floor(n_chunks * TRAIN_RATIO)\n",
    "        val_end = train_end + math.floor(n_chunks * VAL_RATIO)\n",
    "\n",
    "        # Store embeddings for each chunk\n",
    "        for chunk in chunks[:train_end]:\n",
    "            train.append(np.array([song_embeddings[song] for song in chunk]))\n",
    "        for chunk in chunks[train_end:val_end]:\n",
    "            val.append(np.array([song_embeddings[song] for song in chunk]))\n",
    "        for chunk in chunks[val_end:]:\n",
    "            test.append(np.array([song_embeddings[song] for song in chunk]))\n",
    "\n",
    "    # Convert to tensors\n",
    "    train_tensor = torch.tensor(np.array(train))\n",
    "    val_tensor = torch.tensor(np.array(val))\n",
    "    test_tensor = torch.tensor(np.array(test))\n",
    "\n",
    "    # Save results\n",
    "    save_file(\n",
    "        {\"train\": train_tensor, \"validation\": val_tensor, \"test\": test_tensor},\n",
    "        OUTPUT_FILE\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "508b5a4ede0a0bf9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
